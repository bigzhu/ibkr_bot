"""
Binance CSVå¯¼å…¥åŠŸèƒ½æ¨¡å—
ä»ŽBinanceå¯¼å‡ºçš„CSVæ–‡ä»¶å¯¼å…¥è®¢å•æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“
éµå¾ªCLAUDE.mdè§„èŒƒ: fail-faståŽŸåˆ™,ç±»åž‹æ³¨è§£,ç¦ç”¨try-except
"""

import csv
import sys
from pathlib import Path
from typing import Any

from loguru import logger

# å¤„ç†ç›¸å¯¹å¯¼å…¥é—®é¢˜
if __name__ == "__main__":
    # ç›´æŽ¥è¿è¡Œæ—¶æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
    parent_dir = Path(__file__).parent.parent
    sys.path.insert(0, str(parent_dir))

from database.models import BinanceFilledOrder, CSVImportStats
from order_filler.data_access import clear_all_orders, insert_order


class BinanceCSVImporter:
    """
    Binance CSVå¯¼å…¥å™¨
    è´Ÿè´£è§£æžBinanceå¯¼å‡ºçš„CSVæ–‡ä»¶å¹¶å¯¼å…¥åˆ°æ•°æ®åº“
    æ”¯æŒæ ‡å‡†çš„Binance CSVå¯¼å‡ºæ ¼å¼
    """

    def __init__(self) -> None:
        """åˆå§‹åŒ–å¯¼å…¥å™¨"""
        pass

    def import_csv(self, csv_file_path: str, _: bool = True) -> CSVImportStats:
        """
        å¯¼å…¥CSVæ–‡ä»¶

        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            _: æ˜¯å¦é‡ç½®æœªåŒ¹é…æ•°é‡ä¸ºexecutedæ•°é‡(å·²åºŸå¼ƒ,è¡¨ä¼šè¢«æ¸…ç©º)

        Returns:
            å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯
        """
        csv_path = self._resolve_csv_path(csv_file_path)
        cleared_count = self._clear_existing_orders()
        stats_state = self._initialize_stats_state(cleared_count)
        self._process_csv_rows(csv_path, stats_state)

        stats = self._build_stats(csv_path, stats_state)
        logger.info(
            f"CSVå¯¼å…¥å®Œæˆ: æ–°å¢ž{stats.imported_new}æ¡, è·³è¿‡{stats.skipped_existing}æ¡, é‡ç½®{stats.reset_count}æ¡"
        )
        return stats

    def _parse_csv_row(
        self, row: dict[str, str], row_num: int
    ) -> BinanceFilledOrder | None:
        """
        è§£æžCSVè¡Œæ•°æ®ä¸ºBinanceFilledOrderå¯¹è±¡(åŸºäºŽå®žé™…Binance CSVæ ¼å¼)

        Args:
            row: CSVè¡Œæ•°æ®
            row_num: è¡Œå·(ç”¨äºŽé”™è¯¯æŠ¥å‘Š)

        Returns:
            BinanceFilledOrderå¯¹è±¡æˆ–None(è§£æžå¤±è´¥)
        """
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = [
            "Date(UTC)",
            "OrderNo",
            "Pair",
            "Type",
            "Side",
            "Order Price",
            "Order Amount",
            "Time",
            "Executed",
            "Average Price",
            "Trading total",
            "Status",
        ]

        missing_fields = [field for field in required_fields if field not in row]
        if missing_fields:
            logger.warning(f"ç¬¬{row_num}è¡Œç¼ºå°‘å­—æ®µ: {missing_fields}")
            return None

        # ä½¿ç”¨æ¨¡åž‹çš„ from_csv_row æ–¹æ³•åˆ›å»ºå¯¹è±¡
        return BinanceFilledOrder.from_csv_row(row)

    def _resolve_csv_path(self, csv_file_path: str) -> Path:
        """è§£æžå¹¶æ ¡éªŒCSVæ–‡ä»¶è·¯å¾„"""
        csv_path = Path(csv_file_path)
        if not csv_path.exists():
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return csv_path

    def _clear_existing_orders(self) -> int:
        """æ¸…ç©ºçŽ°æœ‰è®¢å•æ•°æ®å¹¶è®°å½•æ•°é‡"""
        cleared_count = clear_all_orders()
        logger.info(f"æ¸…ç©ºçŽ°æœ‰æ•°æ®: {cleared_count} æ¡è®°å½•")
        return cleared_count

    def _initialize_stats_state(self, cleared_count: int) -> dict[str, Any]:
        """åˆå§‹åŒ–å¯¼å…¥çŠ¶æ€ç»Ÿè®¡"""
        return {
            "total_rows": 0,
            "imported_new": 0,
            "skipped_existing": 0,
            "order_filler": 0,
            "reset_count": 0,
            "errors": [],
            "cleared_count": cleared_count,
        }

    def _process_csv_rows(self, csv_path: Path, stats_state: dict[str, Any]) -> None:
        """éåŽ†CSVè¡Œå¹¶æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with csv_path.open(encoding="utf-8-sig") as file:
            reader = csv.DictReader(file)

            for row_num, row in enumerate(reader, 2):
                stats_state["total_rows"] += 1
                self._handle_csv_row(row, row_num, stats_state)

    def _handle_csv_row(
        self, row: dict[str, str], row_num: int, stats_state: dict[str, Any]
    ) -> None:
        """å¤„ç†å•è¡ŒCSVè®°å½•"""
        order = self._parse_csv_row(row, row_num)
        if not order:
            return

        if order.status != "FILLED":
            logger.debug(f"è·³è¿‡æœªå®Œæˆè®¢å•: {order.order_no}, çŠ¶æ€: {order.status}")
            return

        if insert_order(order):
            stats_state["imported_new"] += 1
            stats_state["order_filler"] += 1
        else:
            stats_state["errors"].append(f"ç¬¬{row_num}è¡Œ: æ’å…¥æ•°æ®åº“å¤±è´¥")

    def _build_stats(
        self, csv_path: Path, stats_state: dict[str, Any]
    ) -> CSVImportStats:
        """æž„å»ºæœ€ç»ˆå¯¼å…¥ç»Ÿè®¡å¯¹è±¡"""
        return CSVImportStats(
            file_path=str(csv_path),
            total_rows=stats_state["total_rows"],
            imported_new=stats_state["imported_new"],
            skipped_existing=stats_state["skipped_existing"],
            order_filler=stats_state["order_filler"],
            reset_count=stats_state["reset_count"],
            errors=stats_state["errors"],
        )


def import_binance_csv(csv_file_path: str, _: bool = True) -> CSVImportStats:
    """
    å¯¼å…¥Binance CSVæ–‡ä»¶ - ä¾¿æ·å‡½æ•°

    Args:
        csv_file_path: CSVæ–‡ä»¶è·¯å¾„
        _: æ˜¯å¦é‡ç½®æœªåŒ¹é…æ•°é‡(å·²åºŸå¼ƒ,è¡¨ä¼šè¢«æ¸…ç©º)

    Returns:
        å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯
    """
    importer = BinanceCSVImporter()
    return importer.import_csv(csv_file_path, _)


def main() -> None:
    """æµ‹è¯•CSVå¯¼å…¥åŠŸèƒ½"""
    import sys

    if len(sys.argv) < 2:
        logger.info("ç”¨æ³•: p csv_importer.py CSV_FILE_PATH [--no-reset]")
        logger.info("ç¤ºä¾‹: p csv_importer.py ./binance_trades.csv")
        logger.info("é€‰é¡¹: --no-reset ä¸é‡ç½®çŽ°æœ‰è®¢å•çš„æœªåŒ¹é…æ•°é‡")
        return

    csv_file_path = sys.argv[1]
    reset_unmatched = "--no-reset" not in sys.argv

    logger.info("ðŸ“ Binance CSVå¯¼å…¥æµ‹è¯•")
    logger.info("=" * 50)

    # æ‰§è¡Œå¯¼å…¥
    stats = import_binance_csv(csv_file_path, reset_unmatched)

    # æ˜¾ç¤ºç»“æžœ
    logger.info("âœ… å¯¼å…¥å®Œæˆ!")
    logger.info(f"æ–‡ä»¶: {stats.file_path}")
    logger.info(f"æ€»è¡Œæ•°: {stats.total_rows}")
    logger.info(f"æ–°å¢žè®¢å•: {stats.imported_new}")
    logger.info(f"è·³è¿‡çŽ°æœ‰: {stats.skipped_existing}")
    if reset_unmatched:
        logger.info(f"é‡ç½®æ•°é‡: {stats.reset_count}")
    logger.info(f"é”™è¯¯æ•°: {len(stats.errors)}")

    if stats.errors:
        logger.info("é”™è¯¯è¯¦æƒ…:")
        for error in stats.errors:
            logger.info(f"  - {error}")


if __name__ == "__main__":
    main()
